# í”„ë¡¬í”„íŠ¸ ìˆ˜ì •ë²„ì „
import streamlit as st
import pandas as pd
import shap
import matplotlib.pyplot as plt
from catboost import CatBoostClassifier
from lightgbm import LGBMClassifier
from xgboost import XGBClassifier
from sklearn.ensemble import VotingClassifier
import os
import random
import numpy as np
import tensorflow as tf
from openai import OpenAI
from PyPDF2 import PdfReader
import matplotlib

# í•œê¸€ ê¹¨ì§ ë°©ì§€ ì„¤ì •
matplotlib.rcParams['font.family'] = 'Malgun Gothic'
plt.rcParams['axes.unicode_minus'] = False

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="XAI ê¸°ë°˜ í™˜ì ì˜ˆì¸¡ í•´ì„", layout="wide")
st.title("ğŸ©º ì¤‘í™˜ì íŒ¨í˜ˆì¦ ë§ì¶¤ ì§„ë‹¨ ë„ì›€")

# ì‹œë“œ ê³ ì •
seed_value = 42
os.environ['PYTHONHASHSEED'] = str(seed_value)
random.seed(seed_value)
np.random.seed(seed_value)
tf.random.set_seed(seed_value)

# OpenAI API ì„¤ì •
client = OpenAI(api_key="")

# ì§€ì¹¨ì„œ PDF ë¡œë”© ë° í…ìŠ¤íŠ¸ ì¶”ì¶œ
@st.cache_data
def load_guideline_text():
    try:
        reader = PdfReader("2024 ì§ˆë³‘ê´€ë¦¬ì²­ ì„±ì¸ íŒ¨í˜ˆì¦ ì´ˆê¸°ì¹˜ë£Œì§€ì¹¨ì„œ.pdf")
        text = ""
        for page in reader.pages:
            text += page.extract_text() + "\n"
        return text
    except Exception as e:
        return ""

guideline_text = load_guideline_text()

# ì¢Œì¸¡ ì‚¬ì´ë“œë°” êµ¬ì„±
with st.sidebar:
    st.header("ğŸ›  ì„¤ì •")
    file = st.file_uploader("ğŸ“‚ ì „ì²˜ë¦¬ëœ ì—‘ì…€ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type="xlsx")
    patient_id_input = st.text_input("í™˜ì ID ì…ë ¥")
    selected_id = None
    id_list = []

if 'show_judgement' not in st.session_state:
    st.session_state.show_judgement = False
if 'show_strategy' not in st.session_state:
    st.session_state.show_strategy = False

if file:
    df = pd.read_excel(file)
    st.success(f"âœ… íŒŒì¼ '{file.name}' ì—…ë¡œë“œ ì™„ë£Œ")

    if 'ID' in df.columns:
        id_list = df['ID'].tolist()

        with st.sidebar:
            st.markdown("#### ğŸ”½ í™˜ì ID ì„ íƒ")
            selected_id = st.selectbox(
                "í™˜ì IDë¥¼ ì„ íƒí•˜ì„¸ìš”",
                options=id_list,
                format_func=lambda x: f"í™˜ì ID: {x}"
            )

        if patient_id_input.isdigit():
            patient_id = int(patient_id_input)
        else:
            patient_id = selected_id

        drop_cols = ['ID', 'Adm', 'Death_time', 'Tr_time', 'endtime',
                    'FiO2', 'PCO2', 'PaO2', 'VASO_dose', 'NS',
                    'APACHE II score', 'SOFA', 'Mortality']
        df_clean = df.drop(columns=[col for col in drop_cols if col in df.columns])

        if 'sum' in df_clean.columns and 'Op' in df_clean.columns:
            df_clean.loc[(df_clean['sum'] == 0) & (df_clean['Op'].isna()), 'Op'] = 0
        if 'VASO' in df_clean.columns and 'cc/hr' in df_clean.columns:
            df_clean.loc[(df_clean['VASO'] == 0) & (df_clean['cc/hr'].isna()), 'cc/hr'] = 0

        df_clean = df_clean.dropna()

        if 'result' not in df_clean.columns:
            st.error("'result' ì»¬ëŸ¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
            st.stop()

        y = df_clean['result'].apply(lambda x: 0 if x in [0, 1] else 1)
        X = df_clean.drop(columns=['result'])

        @st.cache_data
        def train_model(X, y):
            cat = CatBoostClassifier(verbose=0, random_seed=42)
            lgbm = LGBMClassifier(random_state=42)
            xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)
            voting_model = VotingClassifier(estimators=[('cat', cat), ('lgbm', lgbm), ('xgb', xgb)], voting='soft')
            voting_model.fit(X, y)
            return voting_model

        model = train_model(X, y)
        explainer = shap.TreeExplainer(model.named_estimators_['cat'])
        shap_values_all = explainer.shap_values(X)
        shap_values = shap_values_all[1] if isinstance(shap_values_all, list) else shap_values_all

        if patient_id in df['ID'].values:
            row_idx = df[df['ID'] == patient_id].index[0]
            patient = X.iloc[[row_idx]]
            pred = model.predict(patient)[0]
            prob = model.predict_proba(patient)[0][1]

            with st.container():
                st.markdown("### ğŸ‘¤ í™˜ì ì •ë³´")
                with st.container(border = True):
                    name = df.loc[row_idx, 'Name'] if 'Name' in df.columns else 'í™ê¸¸ë™'
                    sex_value = df.loc[row_idx, 'Sex'] if 'Sex' in df.columns else None
                    gender = 'ë‚¨ì„±' if sex_value == 0 else ('ì—¬ì„±' if sex_value == 1 else '-')
                    age = df.loc[row_idx, 'Age'] if 'Age' in df.columns else '-'
                    adm = df.loc[row_idx, 'Adm'] if 'Adm' in df.columns else '-'

                    st.write(f"ì´ë¦„: {name}")
                    st.write(f"ì„±ë³„: {gender}")
                    st.write(f"ë‚˜ì´: {age}")
                    st.write(f"ì…ì‹¤ì¼: {adm}")
                    st.write(f"í™˜ì ID: {patient_id}")

            col1, col2 = st.columns(2)

            with col1:
                with st.container(border=True):
                    st.markdown("#### ğŸ“ˆ SHAP Summary Plot")
                    shap_val_row = shap_values[row_idx]
                    fig_summary = plt.figure(figsize=(8, 3))
                    shap.bar_plot(shap_val_row, feature_names=X.columns, max_display=10, show=False)
                    plt.xlabel("SHAP ë³€ìˆ˜ (ì‚¬ë§ë¥  ì˜í–¥)")  # x-axis ì œëª© ë³€ê²½
                    st.pyplot(fig_summary)

                    st.markdown("**ğŸ“‹ ì‚¬ë§ í™•ë¥  ì¦ê°€ì— ê¸°ì—¬í•œ Top 5 ìœ„í—˜ ë³€ìˆ˜**")
                    positive_shap_indices = np.where(shap_val_row > 0)[0]
                    top5_risk_idx = positive_shap_indices[np.argsort(shap_val_row[positive_shap_indices])[::-1][:5]]
                    top5_risk_names = X.columns[top5_risk_idx].tolist()
                    top5_shap_values = shap_val_row[top5_risk_idx]

                    gpt_prompt = f"""
                    ë‹¤ìŒì€ í™˜ìì˜ ì‚¬ë§ë¥ ì— ì˜í–¥ì„ ë¯¸ì¹œ Top 5 ë³€ìˆ˜ì…ë‹ˆë‹¤: {', '.join(top5_risk_names)}.
                    ê° ë³€ìˆ˜ì— ëŒ€í•´ ë‹¤ìŒê³¼ ê°™ì´ ìš”ì•½í•´ ì£¼ì„¸ìš”:
                    - ë³€ìˆ˜ëª…ê³¼ SHAP ê°’ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ë§ë¥  ì˜í–¥ ìˆ˜ì¹˜
                    - ê·¸ ì´ìœ : í•´ë‹¹ ê¸°ëŠ¥ ì €í•˜ or ë³€í™”ë¡œ ì¸í•œ ê°€ëŠ¥ì„±
                    - ì „ì²´ ê¸¸ì´ëŠ” 2ì¤„ ì´ë‚´ë¡œ ìš”ì•½
                    - ì˜ˆì‹œ: 'í˜ˆì†ŒíŒ ìˆ˜ ê°ì†Œë¡œ ì¸í•´ ì‚¬ë§ë¥ ì´ 24.1% ì¦ê°€í–ˆìŒ. ì›ì¸ì€ ì¶œí˜ˆ ìœ„í—˜ ë˜ëŠ” ê°ì—¼ ì¡°ì ˆ ì‹¤íŒ¨ ê°€ëŠ¥ì„± ìˆìŒ.'
                    ì§€ì¹¨ì„œì™€ ëª¨ë¸ í•´ì„ ê²°ê³¼ë¥¼ ì°¸ê³ í•˜ì„¸ìš”.
                    """

                    gpt_response = client.chat.completions.create(
                        model="gpt-4",
                        temperature=0.2,
                        messages=[
                            {"role": "system", "content": "ë‹¹ì‹ ì€ ì¤‘í™˜ìì˜í•™ ì „ë¬¸ì˜ì´ë©° ì˜ë£Œë°ì´í„° í•´ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                            {"role": "user", "content": gpt_prompt}
                        ]
                    )

                    explanation_lines = gpt_response.choices[0].message.content.strip().split("\n")
                    explanations_clean = [line.lstrip("0123456789. ") for line in explanation_lines if line.strip()]

                    df_risk = pd.DataFrame({
                        "ë³€ìˆ˜ëª…": top5_risk_names,
                        "SHAP ê°’": np.round(top5_shap_values, 4),
                        "í•´ì„": explanations_clean
                    })
                    st.table(df_risk)

            with col2:
                with st.container(border=True):
                    st.subheader("ğŸ§  íŒë‹¨")
                    if st.button("íŒë‹¨ ê²°ê³¼ ë³´ê¸°"):
                        with st.expander("ğŸ” GPT íŒë‹¨ í•´ì„ ê²°ê³¼", expanded=True):
                            user_prompt = f"""
                                            í™˜ìì˜ ì‚¬ë§ë¥ ì— ì˜í–¥ì„ ë¯¸ì¹œ ì£¼ìš” ë³€ìˆ˜ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤: {', '.join(top5_risk_names)}.

                                            ì¤‘í™˜ìì˜í•™ ì „ë¬¸ì˜ê°€ ì´í•´í•˜ê¸° ì‰½ë„ë¡ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì˜ë£Œì  íŒë‹¨ì„ ìš”ì•½í•´ ì£¼ì„¸ìš”:

                                            ### ì¶œë ¥ í˜•ì‹ ì˜ˆì‹œ
                                            ğŸ©º 2. ì˜ë£Œì  íŒë‹¨ ìš”ì•½
                                            í˜¸í¡ ê¸°ëŠ¥ ì•…í™”ê°€ ê°€ì¥ í° ë¦¬ìŠ¤í¬ì´ë¯€ë¡œ ì¤‘í™˜ìì‹¤ì—ì„œ ì§‘ì¤‘ì ì¸ í˜¸í¡ ì¹˜ë£Œê°€ í•„ìš”í•´ ë³´ì—¬.

                                            ë‚˜ì´ëŠ” ì¡°ì ˆ ë¶ˆê°€ëŠ¥í•˜ì§€ë§Œ, ë‚˜ì´ë¡œ ì¸í•œ ë¦¬ìŠ¤í¬ê°€ ê½¤ í¬ê¸° ë•Œë¬¸ì— ì „ì²´ì ì¸ ìƒë¦¬ê¸°ëŠ¥ ë³´ì „ì´ ë” ì¤‘ìš”í•´.

                                            ì˜ì‹ ìƒíƒœ(GCS)ê°€ ìœ ì§€ëœ ê±´ ì¢‹ì€ ì‹ í˜¸ì•¼. ì˜ì‹ì´ ì¢‹ìœ¼ë©´ íšŒë³µ ê°€ëŠ¥ì„±ì´ ì¡°ê¸ˆ ë” ìˆì–´.

                                            ìœ„ ì˜ˆì‹œë¥¼ ì°¸ê³ í•˜ì—¬ SHAP Top 5ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”.
                                            """
                            response = client.chat.completions.create(
                                model="gpt-4",
                                temperature=0.2,
                                messages=[
                                    {"role": "system", "content": "ë‹¹ì‹ ì€ ì¤‘í™˜ìì˜í•™+ì˜ë£Œë°ì´í„° í•´ì„ ì „ë¬¸ì˜ì…ë‹ˆë‹¤."},
                                    {"role": "user", "content": user_prompt}
                                ]
                            )
                            st.markdown(response.choices[0].message.content)

                with st.container(border=True):
                    st.subheader("ğŸ’Š ë§ì¶¤í˜• ì¹˜ë£Œ ì „ëµ")
                    if st.button("ì¹˜ë£Œ ì „ëµ ë³´ê¸°"):
                        st.session_state.show_strategy = True

                    if st.session_state.show_strategy:
                        user_prompt = f"""
                                            ì•„ë˜ëŠ” í™˜ìì˜ SHAP Top 5 ë³€ìˆ˜ì…ë‹ˆë‹¤: {', '.join(top5_risk_names)}.

                                            ì´ ë³€ìˆ˜ë“¤ì´ ì˜ë¯¸í•˜ëŠ” ì„ìƒì  ì •ë³´ë¥¼ í† ëŒ€ë¡œ í™˜ì ë§ì¶¤í˜• ì´ˆê¸° ì¹˜ë£Œ ì „ëµì„ ì œì‹œí•´ ì£¼ì„¸ìš”.
                                            PDF ê°€ì´ë“œëŠ” ì°¸ê³ ìš©ìœ¼ë¡œë§Œ ì‚¬ìš©í•˜ì„¸ìš”. ëª¨ë¸ í•´ì„ ê²°ê³¼ì— ê¸°ë°˜í•œ ì‹¤ì œì ì´ê³  êµ¬ì²´ì ì¸ ì¹˜ë£Œ ì œì•ˆì´ì–´ì•¼ í•©ë‹ˆë‹¤.

                                            ## ì§€ì¹¨ì„œ ë°œì·Œë¬¸
                                            ```
                                            {guideline_text[:1500]}
                                            ```
                                            """
                        response = client.chat.completions.create(
                            model="gpt-4",
                            temperature=0.2,
                            messages=[
                                {"role": "system", "content": "ë‹¹ì‹ ì€ ì¤‘í™˜ìì˜í•™ ì „ë¬¸ì˜ì…ë‹ˆë‹¤."},
                                {"role": "user", "content": user_prompt}
                            ]
                        )
                        with st.expander("ğŸ©º GPT ì¹˜ë£Œ ì „ëµ ì œì•ˆ", expanded=True):
                            st.markdown(response.choices[0].message.content)

                with st.container(border=True):
                    st.subheader("ğŸ“ ë‹´ë‹¹ì˜ ì½”ë©˜íŠ¸")
                    comment = st.text_area("ë‹´ë‹¹ì˜ ì½”ë©˜íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”")
                    signer = st.text_input("ì„œëª…")
                    if st.button("ì½”ë©˜íŠ¸ ì €ì¥"):
                        st.success(f"ğŸ’¾ ì½”ë©˜íŠ¸ ì €ì¥ ì™„ë£Œ: {comment} - ì„œëª…: {signer}")

        else:
            st.warning("í•´ë‹¹ IDì— í•´ë‹¹í•˜ëŠ” í™˜ìë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
else:
    st.info("ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ í™˜ì IDë¥¼ ì…ë ¥í•˜ê±°ë‚˜ ì„ íƒí•˜ì„¸ìš”.")
